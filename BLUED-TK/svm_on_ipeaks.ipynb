{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/sf_datasets/Smarter Devices/BLUED_extracted/BLUED-TK\n"
     ]
    }
   ],
   "source": [
    "cd /media/sf_datasets/Smarter\\ Devices/BLUED_extracted/BLUED-TK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PQS.csv', 'dataset_1', 'dataset_10', 'dataset_11', 'dataset_12', 'dataset_13', 'dataset_14', 'dataset_15', 'dataset_16', 'dataset_2', 'dataset_3', 'dataset_4', 'dataset_5', 'dataset_6', 'dataset_7', 'dataset_8', 'dataset_9', 'derived', 'peaks.csv', 'peaks_PQS.txt']\n"
     ]
    }
   ],
   "source": [
    "path = 'events/'\n",
    "list_of_files = os.listdir(path)\n",
    "list_of_files.sort()\n",
    "print (list_of_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs=70\n",
    "\n",
    "#reading the dataframe\n",
    "df=pd.read_table('events/peaks.csv',index_col=0,sep='\\t')\n",
    "total_events=len(df)\n",
    "\n",
    "\n",
    "#converting the string to numpy array\n",
    "def makeArray(text):\n",
    "    text=text.replace(\"[\",\" \").strip()\n",
    "    return np.fromstring(text,sep=' ')\n",
    "\n",
    "df.features=df.features.apply(makeArray)\n",
    "\n",
    "#finding the single event devices\n",
    "freq=df.groupby('label').count()\n",
    "# freq=freq.sort_values(by='features')\n",
    "single_freq=freq[freq.features==1].index\n",
    "# single_freq\n",
    "\n",
    "#eliminating all the single event devices\n",
    "for i in single_freq:\n",
    "    df=(df[df['label']!=i])\n",
    "#df=df[df.label!=111]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2345, 70)\n",
      "(2226,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [2345, 2226]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-95715a50bdca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mv_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mfeature_matrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_matrix\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mm_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mv_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mfeature_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;31m#feature_matrix = preprocessing.StandardScaler().fit(feature_matrix).transform(feature_matrix)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   1687\u001b[0m         \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1689\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstratify\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 181\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2345, 2226]"
     ]
    }
   ],
   "source": [
    "feature_matrix=np.empty((total_events,inputs))\n",
    "#label_matrix=np.zeros((total_events,outputs))\n",
    "\n",
    "ll=np.empty((total_events))\n",
    "count=0\n",
    "for i in df.index:\n",
    "        feature_matrix[count]=df.loc[i].features\n",
    "        ll[count]=df.loc[i].label\n",
    "        count+=1\n",
    "        \n",
    "device_list=list(df.label.unique())\n",
    "label_matrix = np.array(df.label)\n",
    "# for i in range(0,len(ll)):\n",
    "#     label_matrix[i,device_list.index(ll[i])]=1\n",
    "print(feature_matrix.shape)\n",
    "print(label_matrix.shape)   \n",
    "m_f=feature_matrix.mean(axis=0)\n",
    "v_f=feature_matrix.var(axis=0)\n",
    "feature_matrix=(feature_matrix-m_f)/v_f\n",
    "feature_train, feature_test, label_train, label_test = tts(feature_matrix, label_matrix, test_size=0.3, random_state=42)\n",
    "#feature_matrix = preprocessing.StandardScaler().fit(feature_matrix).transform(feature_matrix)\n",
    "print (label_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = []\n",
    "x = np.zeros(60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #stacking all the data into a single array for test train split\n",
    "# for file in list_of_files:\n",
    "#     data = np.loadtxt(path+file,delimiter =',')\n",
    "#     '''for i in range(len(data)):\n",
    "#         for j in range(1:181):\n",
    "#             if(int(data[i,j])<int(data[i,j-1])):\n",
    "#                 continue\n",
    "#             on_data =''' \n",
    "                \n",
    "    \n",
    "#     if file.split(\"_\")[1] == 'labels':\n",
    "#         data = list(data)\n",
    "        \n",
    "#         #data = np.matrix(data).T\n",
    "#         #print (data.shape)\n",
    "        \n",
    "#        # print (data.shape)\n",
    "#         #= np.vstack((np.matrix(y),data))\n",
    "#         y = y+data\n",
    "        \n",
    "#     else:\n",
    "#         for i in range(len(data)):\n",
    "#             norm = np.mean(np.matrix(data[i,:30]))\n",
    "#             data[i,30:]-=norm\n",
    "#             x = np.vstack((x,np.matrix(data[i,30:])))\n",
    "#         print (x.shape)            \n",
    "#         #print(data[:,120:].shape)\n",
    "#         #x = np.vstack((x,data[:,120:]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# y = np.array(y)\n",
    "# print (y.shape)\n",
    "# x = x[1:]\n",
    "# print (x.shape,y.shape)\n",
    "# x_train, x_test, y_train, y_test = tts(x, y, test_size=0.25, random_state=42)   \n",
    "# scalerx = preprocessing.StandardScaler().fit(x_train)\n",
    "# x_train = scalerx.transform(x_train)\n",
    "# x_test = scalerx.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = 50\n",
    "plt.plot(x[p].reshape(-1,1))\n",
    "plt.show()\n",
    "print (y[p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for i in range(len(y_train)):\n",
    "#     if y_train[i] == 211.0:\n",
    "#         #print (y_train[i],x_train[i])\n",
    "#         plt.plot(x_train[i])\n",
    "#         plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''C_range = np.logspace(-2, 10, 13)\n",
    "gamma_range = np.logspace(-9, 3, 13)\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "cv = StratifiedShuffleSplit(n_splits=3, test_size=0.2, random_state=42)\n",
    "grid = GridSearchCV(svm.SVC(), param_grid=param_grid, cv=cv)\n",
    "grid.fit(x,y)\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (grid.best_params_, grid.best_score_))\n",
    "\n",
    "C_2d_range = [1e-2, 1, 1e2]\n",
    "gamma_2d_range = [1e-1, 1, 1e1]\n",
    "classifiers = []\n",
    "for C in C_2d_range:\n",
    "    for gamma in gamma_2d_range:\n",
    "        clf = svm.SVC(C=C, gamma=gamma)\n",
    "        clf.fit(x_train, y_train)\n",
    "        classifiers.append((C, gamma, clf))\n",
    "\n",
    "print (x_train.shape)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataa = pd.read_csv('events/peaks_PQS.txt',sep=',')\n",
    "\n",
    "y = dataa['labels']\n",
    "y1 = dataa[:]\n",
    "del dataa['labels']\n",
    "x= dataa.as_matrix()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import sklearn.utils\n",
    "from sklearn.model_selection import train_test_split as tts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reading the dataframe\n",
    "df=pd.read_table('events/peaks_PQS.txt',index_col=0,sep=',')\n",
    "\n",
    "cols=[str(i) for i in range(70)]\n",
    "cols+=['p','q','s','labels']\n",
    "\n",
    "df.columns=cols\n",
    "#finding the single event devices\n",
    "freq=df.groupby('labels').count()\n",
    "single_freq=freq[freq['0']==1].index\n",
    "print(freq)\n",
    "# df=df.ix[:,'p':]\n",
    "#print(df)\n",
    "# comment to remove p,q,s\n",
    "#del df['72'],df['71'],df['70']\n",
    "\n",
    "# #eliminating refrigerator\n",
    "# #df=(df[df['label']!=111])\n",
    "# #eliminating monitor\n",
    "# # df=(df[df['label']!=140])\n",
    "# # print(len(df))\n",
    "# # printing the values by count\n",
    "# # df.groupby('label').count().sort_values(by='features')\n",
    "\n",
    "\n",
    "#eliminating all the single event devices\n",
    "for i in single_freq:\n",
    "    df=(df[df['labels']!=i])\n",
    "    \n",
    "print(\"Events left after removal of single events %d\"%len(df))\n",
    "\n",
    "#remove irrelavant events\n",
    "uf,lf=df[df.p>20],df[df.p<-20]\n",
    "_df=uf.append(lf)\n",
    "print(\"Events left |p|>30 %d\"%len(_df))\n",
    "    \n",
    "df=_df\n",
    "\n",
    "    \n",
    "device_list=df['labels'].unique()\n",
    "print('output devices %s'%len(device_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert the dataframe to matrix\n",
    "feature_matrix=df.as_matrix()\n",
    "labels=np.array(df['labels'])\n",
    "print(len(set(labels)))\n",
    "inputs=feature_matrix.shape[1]\n",
    "outputs=len(device_list)\n",
    "total_events=len(df)\n",
    "\n",
    "print('Total events is %s'%(total_events))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_matrix=(feature_matrix-feature_matrix.mean(axis=0))/feature_matrix.var(axis=0)\n",
    "\n",
    "feature_train, feature_test, label_train, label_test = tts(feature_matrix, labels, test_size=0.1, random_state=42,stratify=labels)\n",
    "print('feature_train.shape=%s label_train.shape=%s'%(feature_train.shape,label_train.shape)) \n",
    "print('inputs=%d output=%d'%(inputs,outputs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_count = 0\n",
    "test_count = 0\n",
    "for i in label_train:\n",
    "    if i == :\n",
    "        train_count+=1\n",
    "print (train_count)\n",
    "for i in label_test:\n",
    "    if i == 140:\n",
    "        test_count+=1\n",
    "print(test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = svm.SVC(C=1.0,kernel='linear',cache_size=1000,decision_function_shape='ovr',shrinking=True,probability=True)\n",
    "#clf.fit(feature_train, label_train)\n",
    "scores = cross_val_score(clf,feature_matrix ,labels, cv=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = clf.predict(feature_test)\n",
    "result = np.matrix(result).T\n",
    "\n",
    "#print (result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = 0\n",
    "count = 0\n",
    "while index<len(result):\n",
    "    if(result[index,0] == label_test[index]):\n",
    "        count+=1\n",
    "    index +=1\n",
    "#result = clf.predict(feature_test)\n",
    "#result = np.matrix(result).T\n",
    "eff = count/len(label_test)\n",
    "print (eff*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
